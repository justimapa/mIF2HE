{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import tables\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patch(image, x, y, patch_size):\n",
    "    \"\"\"\n",
    "    Extract a patch at a certain position (x,y) of an image, with a certain patch size\n",
    "    \"\"\"\n",
    "    \n",
    "    patch = np.asarray(image.read_region((y-int(patch_size/2),x-int(patch_size/2)), 0, (patch_size, patch_size)))[:,:,0:3]\n",
    "    \n",
    "    return patch\n",
    "        \n",
    "def draw_circle(image, x, y, pixel_value = (0,255,0), radius = 10, thickness = 2):\n",
    "    \"\"\"\n",
    "    Draws a circle around a certain position (x,y) of an image\n",
    "    \"\"\"\n",
    "    \n",
    "    cv2.circle(image, (x,y), radius, pixel_value, thickness)\n",
    "    \n",
    "def is_nucleus(image, x, y, threshold, radius = 10):\n",
    "    \"\"\"\n",
    "    Assess if a nucleaus is present\n",
    "    \"\"\"\n",
    "    \n",
    "    patch = extract_patch(image,x,y,patch_size=radius)\n",
    "    pixel_values = patch.flatten()\n",
    "        \n",
    "    mean = np.mean(pixel_values)\n",
    "    \n",
    "    if mean > threshold: \n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11965</td>\n",
       "      <td>13605</td>\n",
       "      <td>CD3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11945</td>\n",
       "      <td>9636</td>\n",
       "      <td>CD3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11945</td>\n",
       "      <td>9183</td>\n",
       "      <td>CD3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11936</td>\n",
       "      <td>13602</td>\n",
       "      <td>CD3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11930</td>\n",
       "      <td>13734</td>\n",
       "      <td>CD3p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      y  type\n",
       "0  11965  13605  CD3p\n",
       "1  11945   9636  CD3p\n",
       "2  11945   9183  CD3p\n",
       "3  11936  13602  CD3p\n",
       "4  11930  13734  CD3p"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the H&E image\n",
    "HE_open = openslide.OpenSlide('Experiment/HE40X/MELANOMA_AA3_40X/Scan1/MELANOMA_AA3_40X_Scan1.qptiff')\n",
    "\n",
    "# Read H&E cells locations\n",
    "df_1 = pd.read_csv('3_MEL3_HE_cells_locations_NoOffset_1.txt', header = None, names = ['x','y','type'], sep='\\t')\n",
    "df_2 = pd.read_csv('3_MEL3_HE_cells_locations_NoOffset_2_5000_12000.txt', header = None, names = ['x','y','type'], sep='\\t')\n",
    "#df_3 = pd.read_csv('3_MEL3_HE_cells_locations_NoOffset_4_26270_11150.txt', header = None, names = ['x','y','type'], sep='\\t')\n",
    "\n",
    "# Merge the positions\n",
    "Mel3_cells_positions = df_1.merge(df_2, how='outer')\n",
    "#Mel3_cells_positions.to_csv('MEL3_HE_cells_locations.txt', header=None, index = None, sep='\\t', mode='a')\n",
    "\n",
    "#Mel3_cells_positions = pd.read_csv('MEL3_HE_cells_locations.txt', header = None, names = ['x','y','type'], sep='\\t')\n",
    "Mel3_cells_positions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CD11Cp</th>\n",
       "      <td>4977</td>\n",
       "      <td>4977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD20p</th>\n",
       "      <td>37339</td>\n",
       "      <td>37339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD3p</th>\n",
       "      <td>44621</td>\n",
       "      <td>44621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD56p</th>\n",
       "      <td>4280</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD68p</th>\n",
       "      <td>18092</td>\n",
       "      <td>18092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOX10p</th>\n",
       "      <td>96340</td>\n",
       "      <td>96340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x      y\n",
       "type                \n",
       "CD11Cp   4977   4977\n",
       "CD20p   37339  37339\n",
       "CD3p    44621  44621\n",
       "CD56p    4280   4280\n",
       "CD68p   18092  18092\n",
       "SOX10p  96340  96340"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of cells per type \n",
    "Mel3_cells_positions.groupby(by='type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phases = ['train','val']\n",
    "\n",
    "# phenotypes that will be present in the database\n",
    "phenotypes = ['SOX10p','CD3p','CD68p']\n",
    "\n",
    "# defines the label associated to each class\n",
    "phenotype_mask = {'SOX10p':0, 'CD3p': 1, 'CD68p':0}\n",
    "\n",
    "# number of classes\n",
    "nclasses = len(set(phenotype_mask.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "APC = ['CD11Cp' , 'CD68p']\n",
    "Immune = ['CD3p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train dataset... \n",
      "\n",
      "phenotype: SOX10p\n",
      "--> NO Immune \n",
      "\n",
      "phenotype: CD3p\n",
      "--> Immune \n",
      "\n",
      "phenotype: CD68p\n",
      "--> NO Immune \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting train dataset... \\n\")\n",
    "\n",
    "# size of the patch\n",
    "patchsize = 40\n",
    "\n",
    "# number of no-immune cells to be extracted\n",
    "size_no_Immune = 7000\n",
    "\n",
    "# number of immune cells to be extracted \n",
    "size_Immune = 14000\n",
    "\n",
    "# total size \n",
    "size = int((2*size_no_Immune) + (1*size_Immune))\n",
    "\n",
    "# open a hdf5_file  in write mode\n",
    "hdf5_file = tables.open_file(f\"dataset/train_{size}_{patchsize}_{nclasses}classes_CD3p_VS_SOX10p_CD68p_triplefiltered.h5\", mode=\"w\", title=f\"Database test\")\n",
    "\n",
    "# define the shape of a patch, which is its size and the number of channels\n",
    "patch_shape = np.array((patchsize, patchsize, 3))\n",
    "\n",
    "filters = tables.Filters(complevel=6, complib='zlib')\n",
    "\n",
    "# earray for the patch\n",
    "hdf5_file.create_earray(hdf5_file.root, \"patch\", tables.UInt8Atom(), shape=np.append([0], patch_shape),\n",
    "                            chunkshape=np.append([1], patch_shape), filters=filters)\n",
    "\n",
    "# earray for the label\n",
    "hdf5_file.create_earray(hdf5_file.root, \"label\", tables.UInt16Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "\n",
    "# earray for the classsizes (important for neural network)\n",
    "hdf5_file.create_earray(hdf5_file.root, \"classsizes\", tables.UInt16Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "\n",
    "# earray for the image ID\n",
    "hdf5_file.create_earray(hdf5_file.root, \"imgID\", tables.UInt32Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "\n",
    "# counters \n",
    "counter_Immune = 0\n",
    "counter_no_Immune = 0\n",
    "    \n",
    "for phenotype in phenotypes:\n",
    "        \n",
    "    print(f\"phenotype: {phenotype}\")\n",
    "    \n",
    "    if phenotype in Immune:\n",
    "        \n",
    "        print(\"--> Immune \\n\")\n",
    "        \n",
    "        for index, row in df_filtered[df_filtered['type']==phenotype].sample(size_Immune).iterrows():\n",
    "            \n",
    "            # extract the patch\n",
    "            patch = extract_patch(HE_open, row['x'], row['y'], patchsize)\n",
    "            \n",
    "            # append all the information (patch, associated label, ID)\n",
    "            hdf5_file.root.patch.append(patch[None, ::])\n",
    "            hdf5_file.root.label.append([phenotype_mask[phenotype]])\n",
    "            hdf5_file.root.imgID.append([index])\n",
    "            \n",
    "            counter_Immune = counter_Immune + 1\n",
    "            \n",
    "            # remove this sample from the dataframe not to take it back after\n",
    "            df_filtered.drop(index = index, inplace = True)\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        print(\"--> NO Immune \\n\")\n",
    "        \n",
    "        for index, row in df_filtered[df_filtered['type']==phenotype].sample(size_no_Immune).iterrows():\n",
    "            \n",
    "            patch = extract_patch(HE_open, row['x'], row['y'], patchsize)\n",
    "            \n",
    "            hdf5_file.root.patch.append(patch[None, ::])\n",
    "            hdf5_file.root.label.append([phenotype_mask[phenotype]])\n",
    "            hdf5_file.root.imgID.append([index])\n",
    "            \n",
    "            counter_no_Immune = counter_no_Immune + 1\n",
    "            df_filtered.drop(index = index, inplace = True)\n",
    "\n",
    "# add the classsizes for balancing the classes for training\n",
    "hdf5_file.root.classsizes.append([counter_no_Immune])\n",
    "hdf5_file.root.classsizes.append([counter_Immune])\n",
    "\n",
    "# close the file \n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting val dataset... \n",
      "\n",
      "phenotype: SOX10p\n",
      "--> NO Immune \n",
      "\n",
      "phenotype: CD3p\n",
      "--> Immune \n",
      "\n",
      "phenotype: CD68p\n",
      "--> NO Immune \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting val dataset... \\n\")\n",
    "\n",
    "size_no_Immune = 2000\n",
    "size_Immune = 4000\n",
    "size = int((2*size_no_Immune) + (1*size_Immune))\n",
    "\n",
    "\n",
    "    \n",
    "hdf5_file = tables.open_file(f\"dataset/val_{size}_{patchsize}_{nclasses}classes_CD3p_VS_SOX10p_CD68p_triplefiltered.h5\", mode=\"w\", title=f\"Database test\")\n",
    "    \n",
    "patch_shape = np.array((patchsize, patchsize, 3))\n",
    "filters = tables.Filters(complevel=6, complib='zlib')\n",
    "\n",
    "hdf5_file.create_earray(hdf5_file.root, \"patch\", tables.UInt8Atom(), shape=np.append([0], patch_shape),\n",
    "                            chunkshape=np.append([1], patch_shape), filters=filters)\n",
    "\n",
    "hdf5_file.create_earray(hdf5_file.root, \"label\", tables.UInt16Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "    \n",
    "hdf5_file.create_earray(hdf5_file.root, \"classsizes\", tables.UInt16Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "    \n",
    "hdf5_file.create_earray(hdf5_file.root, \"imgID\", tables.UInt32Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "\n",
    "counter_Immune = 0\n",
    "counter_no_Immune = 0\n",
    "    \n",
    "for phenotype in phenotypes:\n",
    "        \n",
    "    print(f\"phenotype: {phenotype}\")\n",
    "    \n",
    "    if phenotype in Immune:\n",
    "        \n",
    "        print(\"--> Immune \\n\")\n",
    "        \n",
    "        for index, row in df_filtered[df_filtered['type']==phenotype].sample(size_Immune).iterrows():\n",
    "            \n",
    "            patch = extract_patch(HE_open, row['x'], row['y'], patchsize)\n",
    "            \n",
    "            hdf5_file.root.patch.append(patch[None, ::])\n",
    "            hdf5_file.root.label.append([phenotype_mask[phenotype]])\n",
    "            hdf5_file.root.imgID.append([index])\n",
    "            \n",
    "            counter_Immune = counter_Immune + 1\n",
    "            df_filtered.drop(index = index, inplace = True)\n",
    "                 \n",
    "    else: \n",
    "        \n",
    "        print(\"--> NO Immune \\n\")\n",
    "        \n",
    "        for index, row in df_filtered[df_filtered['type']==phenotype].sample(size_no_Immune).iterrows():\n",
    "            \n",
    "            patch = extract_patch(HE_open, row['x'], row['y'], patchsize)\n",
    "            \n",
    "            hdf5_file.root.patch.append(patch[None, ::])\n",
    "            hdf5_file.root.label.append([phenotype_mask[phenotype]])\n",
    "            hdf5_file.root.imgID.append([index])\n",
    "            \n",
    "            counter_no_Immune = counter_no_Immune + 1\n",
    "            df_filtered.drop(index = index, inplace = True)\n",
    "            \n",
    "hdf5_file.root.classsizes.append([counter_no_Immune])\n",
    "hdf5_file.root.classsizes.append([counter_Immune])      \n",
    "               \n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test dataset... \n",
      "\n",
      "phenotype: SOX10p\n",
      "--> NO IM \n",
      "\n",
      "phenotype: CD3p\n",
      "--> IM \n",
      "\n",
      "phenotype: CD68p\n",
      "--> NO IM \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting test dataset... \\n\")\n",
    "\n",
    "size_no_Immune = 2700\n",
    "size_Immune = 5400\n",
    "\n",
    "size = int((2*size_no_Immune) + (1*size_Immune))\n",
    "\n",
    "\n",
    "    \n",
    "hdf5_file = tables.open_file(f\"dataset/test_{size}_{patchsize}_{nclasses}classes_CD3p_VS_SOX10p_CD68p.h5\", mode=\"w\", title=f\"Database test\")\n",
    "    \n",
    "patch_shape = np.array((patchsize, patchsize, 3))\n",
    "filters = tables.Filters(complevel=6, complib='zlib')\n",
    "\n",
    "hdf5_file.create_earray(hdf5_file.root, \"patch\", tables.UInt8Atom(), shape=np.append([0], patch_shape),\n",
    "                            chunkshape=np.append([1], patch_shape), filters=filters)\n",
    "\n",
    "hdf5_file.create_earray(hdf5_file.root, \"label\", tables.UInt16Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "    \n",
    "hdf5_file.create_earray(hdf5_file.root, \"imgID\", tables.UInt32Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "\n",
    "hdf5_file.create_earray(hdf5_file.root, \"x\", tables.UInt32Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "\n",
    "hdf5_file.create_earray(hdf5_file.root, \"y\", tables.UInt32Atom(), shape=[0], chunkshape=[1],\n",
    "                            filters=filters)\n",
    "    \n",
    "for phenotype in phenotypes:\n",
    "        \n",
    "    print(f\"phenotype: {phenotype}\")\n",
    "    \n",
    "    if phenotype in Immune:\n",
    "        \n",
    "        print(\"--> IM \\n\")\n",
    "        \n",
    "        for index, row in df_filtered[df_filtered['type']==phenotype].sample(size_Immune).iterrows():\n",
    "            \n",
    "            patch = extract_patch(HE_open, row['x'], row['y'], patchsize)\n",
    "            \n",
    "            hdf5_file.root.patch.append(patch[None, ::])\n",
    "            hdf5_file.root.label.append([phenotype_mask[phenotype]])\n",
    "            hdf5_file.root.imgID.append([index])\n",
    "            hdf5_file.root.x.append([row['x']])\n",
    "            hdf5_file.root.y.append([row['y']])\n",
    "            \n",
    "            \n",
    "            df_filtered.drop(index = index, inplace = True)\n",
    "                 \n",
    "    else: \n",
    "        \n",
    "        print(\"--> NO IM \\n\")\n",
    "        \n",
    "        for index, row in df_filtered[df_filtered['type']==phenotype].sample(size_no_Immune).iterrows():\n",
    "            \n",
    "            patch = extract_patch(HE_open, row['x'], row['y'], patchsize)\n",
    "            \n",
    "            hdf5_file.root.patch.append(patch[None, ::])\n",
    "            hdf5_file.root.label.append([phenotype_mask[phenotype]])\n",
    "            hdf5_file.root.imgID.append([index])\n",
    "            hdf5_file.root.x.append([row['x']])\n",
    "            hdf5_file.root.y.append([row['y']])\n",
    "            \n",
    "            df_filtered.drop(index = index, inplace = True)    \n",
    "               \n",
    "hdf5_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
